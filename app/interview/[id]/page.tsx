'use client'

import { useState, useEffect, useRef, useCallback, useMemo } from 'react'
import { useRouter, useParams, useSearchParams } from 'next/navigation'
import { getFirebaseDb } from '@/src/lib/firebase'
import { doc, getDoc, updateDoc, collection, addDoc, query, orderBy, onSnapshot, serverTimestamp } from 'firebase/firestore'
import { Card, CardHeader, CardTitle, CardDescription, CardContent } from '@/components/ui/card'
import { Button } from '@/components/ui/button'
import { MicIcon, Volume2Icon, PauseIcon, SquareIcon, ArrowLeftIcon, CheckCircleIcon, LoaderIcon } from 'lucide-react'
import Image from 'next/image'
import { InterviewSession, Message, InterviewerProfile } from '@/src/types'

// è³ªå•æ–‡å­—åˆ—ã‚’é…åˆ—ã«ãƒ‘ãƒ¼ã‚¹ã™ã‚‹é–¢æ•°
const parseQuestions = (questionsText?: string, objective?: string): string[] => {
  if (!questionsText && !objective) return []
  
  // questionsTextãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼ˆå„ªå…ˆï¼‰
  if (questionsText && questionsText.trim()) {
    console.log('ğŸ“ questionsTextã‚’ä½¿ç”¨:', questionsText.substring(0, 100))
    // æ”¹è¡Œã§åˆ†å‰²ã—ã€ç©ºè¡Œã‚’é™¤å»
    const lines = questionsText.split('\n').filter(line => line.trim())
    const questions: string[] = []
    
    for (const line of lines) {
      const trimmed = line.trim()
      // ç•ªå·ï¼ˆ1. 2. ãªã©ï¼‰ã‚’é™¤å»
      const cleaned = trimmed.replace(/^\d+[\.\)ã€]\s*/, '').trim()
      if (cleaned && cleaned.length > 0) {
        questions.push(cleaned)
      }
    }
    
    // ãƒ‘ãƒ¼ã‚¹ã§ããŸå ´åˆã¯è¿”ã™
    if (questions.length > 0) {
      console.log('âœ… è³ªå•ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¾ã—ãŸ:', questions.length, 'å€‹')
      return questions
    }
    
    // ãƒ‘ãƒ¼ã‚¹ã§ããªã‹ã£ãŸå ´åˆã¯ã€å…ƒã®æ–‡å­—åˆ—ã‚’ãã®ã¾ã¾è¿”ã™
    if (questionsText.trim().length > 0) {
      console.log('âš ï¸ ãƒ‘ãƒ¼ã‚¹ã§ããªã‹ã£ãŸãŸã‚ã€å…ƒã®æ–‡å­—åˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨')
      return [questionsText.trim()]
    }
  }
  
  // questionsTextãŒãªã„å ´åˆã¯objectiveã‹ã‚‰è³ªå•ã‚’æŠ½å‡º
  if (objective && objective.trim()) {
    // ã¾ãšã€æ”¹è¡Œã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
    let lines = objective.split('\n').map(line => line.trim()).filter(line => line.length > 0)
    
    // æ”¹è¡ŒãŒãªã„å ´åˆã¯ã€ç–‘å•ç¬¦ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹ï¼ˆã€Œï¼Ÿã€ã€Œ?ã€ï¼‰
    if (lines.length <= 1) {
      lines = objective.split(/[ï¼Ÿ\?]/).map(line => line.trim()).filter(line => line.length > 0)
    }
    
    // ãã‚Œã§ã‚‚1ã¤ã—ã‹ãªã„å ´åˆã¯ã€å¥ç‚¹ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
    if (lines.length <= 1) {
      lines = objective.split(/[ã€‚ï¼]/).map(line => line.trim()).filter(line => line.length > 0)
    }
    
    // ãã‚Œã§ã‚‚1ã¤ã—ã‹ãªã„å ´åˆã¯ã€é•·ã„æ–‡ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²ï¼ˆè¤‡æ•°ã®è³ªå•ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ï¼‰
    if (lines.length <= 1 && objective.length > 50) {
      // é•·ã„æ–‡ã‚’ã€Œã€‚ã€ã€Œï¼Ÿã€ã€Œï¼Ÿã€ãªã©ã§åˆ†å‰²
      lines = objective.split(/[ã€‚ï¼Ÿ\?ï¼]/).map(line => line.trim()).filter(line => line.length > 5)
      
      // ãã‚Œã§ã‚‚1ã¤ã—ã‹ãªã„å ´åˆã¯ã€ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²ï¼ˆãŸã ã—ã€çŸ­ã„å˜èªã¯é™¤å¤–ï¼‰
      if (lines.length <= 1) {
        const spaceSplit = objective.split(/\s+/).filter(word => word.length > 10)
        if (spaceSplit.length > 1) {
          // ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²ã—ãŸçµæœãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã€å…ƒã®æ–‡ã‚’é©åˆ‡ã«åˆ†å‰²
          // æ–‡ã®é•·ã•ã«åŸºã¥ã„ã¦åˆ†å‰²ç‚¹ã‚’æ¢ã™
          const sentences: string[] = []
          let currentSentence = ''
          
          for (const word of objective.split(/\s+/)) {
            currentSentence += (currentSentence ? ' ' : '') + word
            // ç–‘å•ç¬¦ã‚„å¥ç‚¹ãŒã‚ã‚‹å ´åˆã€ã¾ãŸã¯é•·ã•ãŒä¸€å®šä»¥ä¸Šã®å ´åˆã«åˆ†å‰²
            if (word.match(/[ï¼Ÿ\?ã€‚ï¼]$/) || currentSentence.length > 40) {
              if (currentSentence.trim().length > 5) {
                sentences.push(currentSentence.trim())
                currentSentence = ''
              }
            }
          }
          
          if (currentSentence.trim().length > 5) {
            sentences.push(currentSentence.trim())
          }
          
          if (sentences.length > 0) {
            lines = sentences
          }
        }
      }
    }
    
    // æŠ½å‡ºã§ããŸå ´åˆã¯è¿”ã™
    if (lines.length > 0) {
      return lines
    }
    
    // ãã‚Œã§ã‚‚æŠ½å‡ºã§ããªã‘ã‚Œã°ã€objectiveå…¨ä½“ã‚’1ã¤ã®è³ªå•ã¨ã—ã¦æ‰±ã†
    return [objective.trim()]
  }
  
  return []
}

export default function VoiceChatInterviewPage() {
  const params = useParams()
  const searchParams = useSearchParams()
  const interviewId = params.id as string
  const router = useRouter()
  const isTestMode = searchParams.get('mode') === 'test'
  const [interview, setInterview] = useState<InterviewSession | null>(null)
  const [interviewerProfile, setInterviewerProfile] = useState<InterviewerProfile | null>(null)
  const [messages, setMessages] = useState<Message[]>([])
  const [questions, setQuestions] = useState<string[]>([])
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0)
  const [loading, setLoading] = useState(true)
  const [listening, setListening] = useState(false) // éŸ³å£°èªè­˜ä¸­ã‹ã©ã†ã‹
  const [playing, setPlaying] = useState(false)
  const [playingQuestion, setPlayingQuestion] = useState(false)
  const [processing, setProcessing] = useState(false)
  const [currentTranscript, setCurrentTranscript] = useState('')
  const [volume, setVolume] = useState(1.0) // éŸ³é‡ï¼ˆ0.0-1.0ï¼‰
  const [progressEvaluation, setProgressEvaluation] = useState<any>(null)
  const [evaluatingProgress, setEvaluatingProgress] = useState(false)
  const [startTime, setStartTime] = useState<Date | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioElementRef = useRef<HTMLAudioElement | null>(null)
  const recognitionRef = useRef<any>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const isRecognitionActiveRef = useRef<boolean>(false)
  const questionPlaybackStartTimeRef = useRef<number>(0) // è³ªå•ã®èª­ã¿ä¸Šã’é–‹å§‹æ™‚åˆ»

  const playKnockSound = useCallback(async () => {
    try {
      console.log('ğŸ”Š åŠ¹æœéŸ³ã‚’å†ç”Ÿã—ã‚ˆã†ã¨ã—ã¦ã„ã¾ã™...')
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
      if (!AudioContextClass) {
        console.error('âŒ AudioContextãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“')
        return
      }
      
      const audioContext = new AudioContextClass()
      if (audioContext.state === 'suspended') {
        try {
          await audioContext.resume()
        } catch (error: any) {
          console.error('âŒ AudioContextã®resumeã«å¤±æ•—:', error)
          return
        }
      }
      
      if (audioContext.state !== 'running') {
        await new Promise(resolve => setTimeout(resolve, 100))
        if (audioContext.state === 'suspended') {
          try {
            await audioContext.resume()
          } catch (error: any) {
            console.error('âŒ AudioContextã®resumeå†è©¦è¡Œã«å¤±æ•—:', error)
            return
          }
        }
      }
      
      const oscillator = audioContext.createOscillator()
      const gainNode = audioContext.createGain()
      oscillator.connect(gainNode)
      gainNode.connect(audioContext.destination)
      oscillator.type = 'sine'
      oscillator.frequency.setValueAtTime(200, audioContext.currentTime)
      oscillator.frequency.exponentialRampToValueAtTime(100, audioContext.currentTime + 0.1)
      gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.1)
      oscillator.start(audioContext.currentTime)
      oscillator.stop(audioContext.currentTime + 0.1)
      
      oscillator.onended = () => {
        setTimeout(() => {
          audioContext.close().catch((error: any) => {
            console.warn('âš ï¸ AudioContextã®closeã«å¤±æ•—:', error)
          })
        }, 100)
      }
    } catch (error) {
      console.error('âŒ åŠ¹æœéŸ³ã®å†ç”Ÿã‚¨ãƒ©ãƒ¼:', error)
    }
  }, [])

  const handlePlayQuestion = useCallback(async (questionIndex: number) => {
    if (questionIndex >= questions.length || !questions[questionIndex] || !interviewerProfile) {
      console.warn('âš ï¸ è³ªå•ã®èª­ã¿ä¸Šã’ã‚’ã‚¹ã‚­ãƒƒãƒ—:', { questionIndex, questionsLength: questions.length, interviewerProfile: !!interviewerProfile })
      return
    }

    let question = questions[questionIndex]
    const interviewerName = interviewerProfile.name || interview?.interviewerName || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'
    question = question.replace(/ã‚ãªãŸã®åå‰/g, interviewerName).replace(/ã‚ãªãŸã®åå‰/g, interviewerName)

    console.log('ğŸ¤ è³ªå•ã‚’èª­ã¿ä¸Šã’ã¾ã™:', { questionText: question.substring(0, 100) })

    try {
      setPlayingQuestion(true)
      const response = await fetch('/api/text-to-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: question,
          voiceType: interviewerProfile.voiceSettings?.voiceType || 'Puck',
          speed: interviewerProfile.voiceSettings?.speed || 1.0,
        }),
      })

      if (!response.ok) throw new Error(`éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${response.status}`)

      const audioBlob = await response.blob()
      const audioUrl = URL.createObjectURL(audioBlob)
      
      if (audioElementRef.current) {
        audioElementRef.current.pause()
      }
      const audio = new Audio(audioUrl)
      audioElementRef.current = audio
      audio.volume = volume
      
      questionPlaybackStartTimeRef.current = Date.now()
      
      audio.onended = () => {
        setPlayingQuestion(false)
        URL.revokeObjectURL(audioUrl)
        addDoc(collection(getFirebaseDb(), `interviews/${interviewId}/messages`), {
          role: 'interviewer',
          content: question,
          timestamp: serverTimestamp(),
        }).catch(saveError => console.error('âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰:', saveError))
        
        setTimeout(() => {
          if (!playingQuestion && !processing) {
            startListening()
          }
        }, 2000)
      }
      
      audio.onerror = (e) => {
        console.error('âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼:', e)
        setPlayingQuestion(false)
        URL.revokeObjectURL(audioUrl)
        alert('âŒ éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ')
      }
      
      await audio.play()
    } catch (error) {
      console.error('âŒ è³ªå•èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼:', error)
      setPlayingQuestion(false)
      alert(`âŒ è³ªå•ã®èª­ã¿ä¸Šã’ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`)
    }
  }, [questions, interviewerProfile, interviewId, volume, interview?.interviewerName])

  const handleStopAudio = useCallback(() => {
    if (audioElementRef.current) {
      audioElementRef.current.pause()
      audioElementRef.current.currentTime = 0
      setPlaying(false)
    }
  }, [])

  useEffect(() => {
    if (audioElementRef.current) {
      audioElementRef.current.volume = volume
    }
  }, [volume])

  const loadInterviewData = useCallback(async () => {
    setLoading(true)
    try {
      const firestoreDb = getFirebaseDb()
      const docRef = doc(firestoreDb, 'interviews', interviewId)
      const docSnap = await getDoc(docRef)

      if (docSnap.exists()) {
        const data = docSnap.data() as any
        const loadedInterview: InterviewSession = {
          id: docSnap.id,
          ...data,
          createdAt: data.createdAt?.toDate(),
          updatedAt: data.updatedAt?.toDate(),
        }
        setInterview(loadedInterview)
        
        const parsedQuestions = parseQuestions(loadedInterview.questions, loadedInterview.objective)
        if (parsedQuestions.length === 0) {
          console.warn('âš ï¸ è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚')
        }
        setQuestions(parsedQuestions)

        if (loadedInterview.interviewerId) {
          const interviewerDocRef = doc(getFirebaseDb(), 'interviewers', loadedInterview.interviewerId)
          const interviewerDocSnap = await getDoc(interviewerDocRef)
          if (interviewerDocSnap.exists()) {
            const interviewerData = interviewerDocSnap.data() as any
            setInterviewerProfile({
              id: interviewerDocSnap.id,
              ...interviewerData,
              createdAt: interviewerData.createdAt?.toDate(),
              updatedAt: interviewerData.updatedAt?.toDate(),
            })
          }
        }
      } else {
        alert('âš ï¸ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        router.push('/')
      }
    } catch (error) {
      console.error('Error loading interview data:', error)
      alert('âŒ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ')
    } finally {
      setLoading(false)
    }
  }, [interviewId, router])

  const evaluateProgress = useCallback(async (conversationHistory: Array<{ role: string, content: string }>) => {
    if (!interview?.objective || !interview?.knowledgeBaseIds) return
    setEvaluatingProgress(true)
    try {
      const response = await fetch('/api/interview/evaluate-progress', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          conversationHistory,
          objective: interview.objective,
          interviewPurpose: interview.interviewPurpose || '',
          knowledgeBaseIds: interview.knowledgeBaseIds || [],
        }),
      })
      if (!response.ok) throw new Error('é€²æ—è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ')
      const data = await response.json()
      if (data.success && data.evaluation) {
        setProgressEvaluation(data.evaluation)
      }
    } catch (error) {
      console.error('Error evaluating progress:', error)
    } finally {
      setEvaluatingProgress(false)
    }
  }, [interview?.objective, interview?.knowledgeBaseIds, interview?.interviewPurpose])

  const setupMessagesListener = useCallback(() => {
    const q = query(collection(getFirebaseDb(), `interviews/${interviewId}/messages`), orderBy('timestamp', 'asc'))
    const unsubscribe = onSnapshot(q, (snapshot) => {
      const newMessages = snapshot.docs.map(doc => ({
        id: doc.id,
        ...doc.data(),
        timestamp: doc.data().timestamp?.toDate(),
      })) as Message[]
      setMessages(newMessages)
      
      if (newMessages.length > 0 && interview?.objective) {
        const conversationHistory = newMessages.map(msg => ({ role: msg.role, content: msg.content || '' }))
        setTimeout(() => evaluateProgress(conversationHistory), 2000)
      }
    }, (error) => {
      console.error('Error listening to messages:', error)
    })
    return unsubscribe
  }, [interviewId, interview?.objective, evaluateProgress])

  useEffect(() => {
    if (interviewId) {
      loadInterviewData()
      const unsubscribe = setupMessagesListener()
      initializeSpeechRecognition()
      return () => {
        unsubscribe?.()
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') mediaRecorderRef.current.stop()
        if (recognitionRef.current && isRecognitionActiveRef.current) {
          try {
            recognitionRef.current.stop()
          } catch (e) { /* ignore */ }
          isRecognitionActiveRef.current = false
        }
        streamRef.current?.getTracks().forEach(track => track.stop())
        if (silenceTimeoutRef.current) clearTimeout(silenceTimeoutRef.current)
      }
    }
  }, [interviewId, loadInterviewData, setupMessagesListener])
  
  const generateIntroductionMessage = useCallback((): string => {
    if (!interview) return ''
    const parts: string[] = []
    const interviewerName = interviewerProfile?.name || interview.interviewerName || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'
    parts.push('æœ¬æ—¥ã¯ãŠæ™‚é–“ã‚’ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚')
    parts.push(`ç§ã€${interviewerName}ã¨ç”³ã—ã¾ã™ã€‚`)
    if (interview.interviewPurpose) parts.push(`æœ¬æ—¥ã¯ã€${interview.interviewPurpose}ã«ã¤ã„ã¦ãŠè©±ã‚’ä¼ºã„ãŸã„ã¨æ€ã£ã¦ã„ã¾ã™ã€‚`)
    if (interview.targetAudience) parts.push(`${interview.targetAudience}ã®æ–¹ã€…ã«å‘ã‘ã¦ã€`)
    if (interview.mediaType) parts.push(`${interview.mediaType}ã«æ²è¼‰äºˆå®šã§ã™ã€‚`)
    if (interview.objective) {
      const objectives = interview.objective.split('\n').filter((line: string) => line.trim()).slice(0, 3)
      if (objectives.length > 0) {
        parts.push('ç‰¹ã«ã€ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦è©³ã—ããŠèã‹ã›ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚')
        objectives.forEach((obj: string, index: number) => {
          const cleaned = obj.replace(/^[-*â€¢]\s*/, '').trim()
          if (cleaned) {
            if (index === objectives.length - 1) {
              parts.push(`${index + 1}ã¤ç›®ã¯ã€${cleaned}ã«ã¤ã„ã¦ã§ã™ã€‚`)
            } else {
              parts.push(`${index + 1}ã¤ç›®ã¯ã€${cleaned}ã€`)
            }
          }
        })
      }
    }
    parts.push('ãã‚Œã§ã¯ã€ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚')
    return parts.join(' ')
  }, [interview, interviewerProfile])

  const handlePlayIntroduction = useCallback(async (): Promise<void> => {
    if (!interviewerProfile) return
    const introductionText = generateIntroductionMessage()
    if (!introductionText) return

    setPlayingQuestion(true)
    try {
      const response = await fetch('/api/text-to-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: introductionText,
          voiceType: interviewerProfile.voiceSettings?.voiceType || 'Puck',
          speed: interviewerProfile.voiceSettings?.speed || 1.0,
        }),
      })
      if (!response.ok) throw new Error(`éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${response.status}`)
      const audioBlob = await response.blob()
      const audioUrl = URL.createObjectURL(audioBlob)
      if (audioElementRef.current) audioElementRef.current.pause()
      const audio = new Audio(audioUrl)
      audioElementRef.current = audio
      audio.volume = volume
      
      await new Promise<void>((resolve, reject) => {
        audio.onended = () => {
          setPlayingQuestion(false)
          URL.revokeObjectURL(audioUrl)
          resolve()
        }
        audio.onerror = (e) => {
          setPlayingQuestion(false)
          URL.revokeObjectURL(audioUrl)
          reject(new Error('éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ'))
        }
        audio.play().catch(reject)
      })
    } catch (error) {
      console.error('âŒ å°å…¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼:', error)
      setPlayingQuestion(false)
      throw error
    }
  }, [interviewerProfile, generateIntroductionMessage, volume])

  const [hasStarted, setHasStarted] = useState(false)
  
  useEffect(() => {
    if (!isTestMode && questions.length > 0 && currentQuestionIndex === 0 && messages.length === 0 && !playingQuestion && !hasStarted && interviewerProfile && interview && !loading) {
      setHasStarted(true)
      setTimeout(async () => {
        try {
          await handlePlayIntroduction()
          setTimeout(() => handlePlayQuestion(0), 500)
        } catch (error) {
          console.error('âŒ å°å…¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯æœ€åˆã®è³ªå•ã®èª­ã¿ä¸Šã’ã«å¤±æ•—:', error)
          handlePlayQuestion(0)
        }
      }, 100)
    }
  }, [questions, currentQuestionIndex, messages.length, interviewerProfile, interview, loading, playingQuestion, handlePlayQuestion, handlePlayIntroduction, isTestMode, hasStarted])
  
  const handleStartTestInterview = async () => {
    if (questions.length === 0 || !interviewerProfile) {
      alert('è³ªå•ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“')
      return
    }
    setHasStarted(true)
    await handlePlayQuestion(0)
  }

  const initializeSpeechRecognition = () => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
      if (!SpeechRecognition) {
        alert('âŒ ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚Chromeã¾ãŸã¯Edgeãƒ–ãƒ©ã‚¦ã‚¶ã‚’ã”ä½¿ç”¨ãã ã•ã„ã€‚')
        return
      }
      const recognition = new SpeechRecognition()
      recognition.continuous = true
      recognition.interimResults = true
      recognition.lang = 'ja-JP'
      
      const transcriptRef = { current: '' }
      
      recognition.onresult = (event: any) => {
        if ((Date.now() - questionPlaybackStartTimeRef.current) < 5000) return
        
        let interimTranscript = ''
        let newFinalTranscript = ''
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript
          if (event.results[i].isFinal) {
            newFinalTranscript += transcript
          } else {
            interimTranscript += transcript
          }
        }
        
        if (newFinalTranscript) transcriptRef.current += newFinalTranscript
        setCurrentTranscript(transcriptRef.current + interimTranscript)
        
        if (silenceTimeoutRef.current) clearTimeout(silenceTimeoutRef.current)
        
        if (newFinalTranscript && transcriptRef.current.trim().length >= 10) {
          silenceTimeoutRef.current = setTimeout(() => {
            if (transcriptRef.current.trim().length >= 10 && !processing && !playingQuestion) {
              const responseText = transcriptRef.current.trim()
              transcriptRef.current = ''
              processResponse(responseText)
            }
          }, 5000)
        }
      }
      
      recognition.onstart = () => {
        isRecognitionActiveRef.current = true
        setListening(true)
      }
      
      recognition.onerror = (event: any) => {
        if (event.error === 'aborted' || event.error === 'no-speech') {
          isRecognitionActiveRef.current = false
          if (event.error === 'no-speech' && transcriptRef.current.trim().length >= 10) {
             processResponse(transcriptRef.current.trim())
             transcriptRef.current = ''
          } else if (!processing && !playingQuestion && !isRecognitionActiveRef.current) {
            setTimeout(() => {
              if (!processing && !playingQuestion && recognitionRef.current && !isRecognitionActiveRef.current) {
                try {
                  recognitionRef.current.start()
                } catch (e: any) {
                  if (e.name !== 'InvalidStateError') console.error('éŸ³å£°èªè­˜ã®å†é–‹ã«å¤±æ•—:', e)
                }
              }
            }, 1000)
          }
          return
        }
        console.error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error)
        isRecognitionActiveRef.current = false
      }
      
      recognition.onend = () => {
        isRecognitionActiveRef.current = false
        if (processing || playingQuestion) return
        
        const currentTranscriptText = transcriptRef.current.trim()
        if (currentTranscriptText.length >= 10) {
          setTimeout(() => {
            if (!processing && !playingQuestion && transcriptRef.current.trim().length >= 10) {
              processResponse(transcriptRef.current.trim())
              transcriptRef.current = ''
            }
          }, 2000)
        } else {
          setTimeout(() => {
            if (!processing && !playingQuestion && recognitionRef.current && !isRecognitionActiveRef.current) {
              try {
                recognitionRef.current.start()
              } catch (e: any) {
                if (e.name !== 'InvalidStateError') console.error('éŸ³å£°èªè­˜ã®å†é–‹ã«å¤±æ•—:', e)
              }
            }
          }, 1000)
        }
      }
      recognitionRef.current = recognition
    }
  }

  const startListening = async () => {
    if (playingQuestion || processing) {
      setTimeout(() => {
        if (!playingQuestion && !processing) startListening()
      }, 1000)
      return
    }
    
    if (!recognitionRef.current) initializeSpeechRecognition()
    
    try {
      if (!streamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        streamRef.current = stream
        const mediaRecorder = new MediaRecorder(stream)
        mediaRecorderRef.current = mediaRecorder
        audioChunksRef.current = []
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) audioChunksRef.current.push(event.data)
        }
        mediaRecorder.start()
      }
      
      if (recognitionRef.current && !isRecognitionActiveRef.current) {
        recognitionRef.current.start()
      }
      setListening(true)
      setCurrentTranscript('')
    } catch (error) {
      console.error('Error starting listening:', error)
      alert('âŒ ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒã‚¤ã‚¯ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚')
    }
  }

  const processResponse = async (transcript: string) => {
    if (processing || !transcript.trim()) return
    setProcessing(true)
    setListening(false)
    playKnockSound().catch(e => console.error('âŒ åŠ¹æœéŸ³ã®å†ç”Ÿã«å¤±æ•—:', e))
    
    if (recognitionRef.current && isRecognitionActiveRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) { console.error('éŸ³å£°èªè­˜ã®åœæ­¢ã‚¨ãƒ©ãƒ¼:', e) }
      isRecognitionActiveRef.current = false
    }
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') mediaRecorderRef.current.stop()

    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' })
      const userResponse = transcript.trim()
      
      const interviewDocRef = doc(getFirebaseDb(), 'interviews', interviewId)
      const interviewDocSnap = await getDoc(interviewDocRef)
      if (interviewDocSnap.exists() && interviewDocSnap.data().rehearsalMessages?.length > 0) {
        await updateDoc(interviewDocRef, { rehearsalMessages: [], updatedAt: serverTimestamp() })
      }
      
      await addDoc(collection(getFirebaseDb(), `interviews/${interviewId}/messages`), {
        role: 'interviewee',
        content: userResponse,
        audioUrl: URL.createObjectURL(audioBlob),
        timestamp: serverTimestamp(),
      })
      
      audioChunksRef.current = []
      if (streamRef.current && mediaRecorderRef.current) {
        mediaRecorderRef.current = new MediaRecorder(streamRef.current)
        mediaRecorderRef.current.ondataavailable = (event) => {
          if (event.data.size > 0) audioChunksRef.current.push(event.data)
        }
        mediaRecorderRef.current.start()
      }
      
      // ç›¸æ§Œç”Ÿæˆ
      try {
        const reactionResponse = await fetch('/api/interview/generate-reaction', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ userResponse, interviewerPrompt: interviewerProfile?.prompt || '', reactionPatterns: interviewerProfile?.reactionPatterns || '' }),
        })
        if (reactionResponse.ok) {
          const reactionData = await reactionResponse.json()
          if (reactionData.reaction) {
            const reactionAudioResponse = await fetch('/api/text-to-speech', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ text: reactionData.reaction, voiceType: interviewerProfile?.voiceSettings?.voiceType || 'Puck', speed: interviewerProfile?.voiceSettings?.speed || 1.0 }),
            })
            if (reactionAudioResponse.ok) {
              const reactionAudioBlob = await reactionAudioResponse.blob()
              const reactionAudioUrl = URL.createObjectURL(reactionAudioBlob)
              const reactionAudio = new Audio(reactionAudioUrl)
              await reactionAudio.play()
              reactionAudio.onended = () => URL.revokeObjectURL(reactionAudioUrl)
              await addDoc(collection(getFirebaseDb(), `interviews/${interviewId}/messages`), {
                role: 'interviewer',
                content: reactionData.reaction,
                audioUrl: reactionAudioUrl,
                timestamp: serverTimestamp(),
              })
            }
          }
        }
      } catch (error) { console.error('âŒ åå¿œç”Ÿæˆã‚¨ãƒ©ãƒ¼:', error) }
      
      const conversationHistory = [...messages, { role: 'interviewee', content: userResponse }].map(msg => ({ role: msg.role, content: msg.content || '' }))
      
      let needsMoreInfo = false
      let suggestedAngle = ''
      // å›ç­”è©•ä¾¡
      try {
        const evaluationResponse = await fetch('/api/interview/evaluate-response', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ question: questions[currentQuestionIndex], userResponse, interviewObjective: interview?.objective || '', conversationHistory }),
        })
        if (evaluationResponse.ok) {
          const evaluationData = await evaluationResponse.json()
          if (evaluationData.evaluation && !evaluationData.evaluation.isSufficient) {
            needsMoreInfo = true
            suggestedAngle = evaluationData.evaluation.suggestedAngle || evaluationData.evaluation.missingElements?.join('ã€') || ''
          }
        }
      } catch (error) { console.error('Error evaluating response:', error) }

      // è¿½åŠ è³ªå•ç”Ÿæˆ
      try {
        const response = await fetch('/api/interview/generate-follow-up', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ question: questions[currentQuestionIndex], userResponse, interviewObjective: interview?.objective || '', interviewerPrompt: interviewerProfile?.prompt || '', knowledgeBaseIds: interview?.knowledgeBaseIds || [], conversationHistory, needsMoreInfo, suggestedAngle }),
        })
        if (response.ok) {
          const data = await response.json()
          if (data.question) {
            const newQuestions = [...questions, data.question]
            setQuestions(newQuestions)
            const followUpIndex = newQuestions.length - 1
            setCurrentQuestionIndex(followUpIndex)
            setTimeout(() => handlePlayQuestion(followUpIndex), 1000)
            setProcessing(false)
            setCurrentTranscript('')
            return
          }
        }
      } catch (error) { console.error('Error generating follow-up question:', error) }

      // å‹•çš„è³ªå•ç”Ÿæˆ
      try {
        playKnockSound().catch(e => console.error('âŒ åŠ¹æœéŸ³ã®å†ç”Ÿã«å¤±æ•—:', e))
        const nextQuestionResponse = await fetch('/api/interview/generate-next-question', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ conversationHistory, interviewPurpose: interview?.interviewPurpose || '', targetAudience: interview?.targetAudience || '', mediaType: interview?.mediaType || '', objective: interview?.objective || '', knowledgeBaseIds: interview?.knowledgeBaseIds || [] }),
        })
        if (nextQuestionResponse.ok) {
          const nextQuestionData = await nextQuestionResponse.json()
          if (nextQuestionData.question) {
            const newQuestions = [...questions, nextQuestionData.question]
            setQuestions(newQuestions)
            const newQuestionIndex = newQuestions.length - 1
            setCurrentQuestionIndex(newQuestionIndex)
            setTimeout(() => handlePlayQuestion(newQuestionIndex), 1000)
            setProcessing(false)
            setCurrentTranscript('')
            return
          }
        }
      } catch (error) { console.error('Error generating next question dynamically:', error) }

      // æ¬¡ã®è³ªå•ã¸
      const nextIndex = currentQuestionIndex + 1
      if (nextIndex < questions.length) {
        setCurrentQuestionIndex(nextIndex)
        setTimeout(() => handlePlayQuestion(nextIndex), 1000)
      } else {
        if (userResponse.length < 10) {
          // çŸ­ã„å›ç­”ã®å ´åˆã¯å®Œäº†ã—ãªã„
          return
        }
        
        // å®Œäº†å‡¦ç†
        const finalMessage = 'ã‚‚ã—è¨€ã„æ®‹ã—ãŸã“ã¨ãŒã‚ã‚Œã°ãœã²ãŠè©±ãã ã•ã„ã€‚'
        try {
          if (interviewerProfile) {
            const finalAudioResponse = await fetch('/api/text-to-speech', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ text: finalMessage, voiceType: interviewerProfile.voiceSettings?.voiceType || 'Puck', speed: interviewerProfile.voiceSettings?.speed || 1.0 }),
            })
            if (finalAudioResponse.ok) {
              const finalAudioBlob = await finalAudioResponse.blob()
              if (finalAudioBlob.size > 0) {
                const finalAudioUrl = URL.createObjectURL(finalAudioBlob)
                const finalAudio = new Audio(finalAudioUrl)
                await finalAudio.play()
                finalAudio.onended = () => URL.revokeObjectURL(finalAudioUrl)
                await addDoc(collection(getFirebaseDb(), `interviews/${interviewId}/messages`), {
                  role: 'interviewer',
                  content: finalMessage,
                  audioUrl: finalAudioUrl,
                  timestamp: serverTimestamp(),
                })
              }
            }
          }
        } catch (error) { console.error('Error adding final message:', error) }
        
        await updateDoc(doc(getFirebaseDb(), 'interviews', interviewId), {
          status: 'completed',
          updatedAt: serverTimestamp(),
        })
        alert('âœ… ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
      }
    } catch (error) {
      console.error('Error processing response:', error)
      alert('âŒ å›ç­”ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ')
    } finally {
      setProcessing(false)
      setCurrentTranscript('')
    }
  }

  useEffect(() => {
    if (messages.length > 0 && !startTime) {
      setStartTime(new Date())
    }
  }, [messages.length, startTime])
  
  const currentQuestion = useMemo(() => questions[currentQuestionIndex], [questions, currentQuestionIndex]);
  const isInterviewComplete = useMemo(() => questions.length === 0 || currentQuestionIndex >= questions.length, [questions, currentQuestionIndex]);

  return (
    <>
      {loading ? (
        <div className="min-h-screen flex items-center justify-center bg-gray-50 dark:bg-gray-900">
          <div className="text-center">
            <LoaderIcon className="w-12 h-12 animate-spin text-purple-600 mx-auto mb-4" />
            <p className="text-gray-600 dark:text-gray-400">èª­ã¿è¾¼ã¿ä¸­...</p>
          </div>
        </div>
      ) : !interview ? (
        <div className="min-h-screen flex items-center justify-center bg-gray-50 dark:bg-gray-900">
          <Card className="p-6 text-center">
            <h2 className="text-xl font-bold text-gray-900 dark:text-gray-100 mb-4">ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</h2>
            <Button onClick={() => router.push('/')}>ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹</Button>
          </Card>
        </div>
      ) : (
    <div className="min-h-screen bg-gray-50 dark:bg-gray-900">
      {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
      <div className="bg-white dark:bg-gray-800 border-b border-gray-200 dark:border-gray-700 sticky top-0 z-10">
        <div className="max-w-md mx-auto px-4 py-4">
          <h1 className="text-lg font-bold text-gray-900 dark:text-gray-100">
            {interview.title || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼'}
          </h1>
          {interview.intervieweeName && (
            <p className="text-sm text-gray-600 dark:text-gray-400 mt-1">
              {interview.intervieweeName}
              {interview.intervieweeCompany && ` (${interview.intervieweeCompany})`}
            </p>
          )}
          
          {/* éŸ³é‡èª¿æ•´ã¨åœæ­¢ãƒœã‚¿ãƒ³ */}
          {!isInterviewComplete && questions.length > 0 && (
            <div className="mt-4 space-y-3">
              {/* éŸ³é‡èª¿æ•´ */}
              <div className="flex items-center gap-2">
                <span className="text-xs text-gray-600 dark:text-gray-400 w-12">éŸ³é‡</span>
                <input
                  type="range"
                  min="0"
                  max="1"
                  step="0.1"
                  value={volume}
                  onChange={(e) => setVolume(parseFloat(e.target.value))}
                  className="flex-1 h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                />
                <span className="text-xs text-gray-600 dark:text-gray-400 w-8 text-right">
                  {Math.round(volume * 100)}%
                </span>
              </div>
              
              {/* åœæ­¢ãƒœã‚¿ãƒ³ */}
              <Button
                onClick={async () => {
                  console.log('â¹ï¸ åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ')
                  if (playing) handleStopAudio()
                  if (playingQuestion) {
                    if (audioElementRef.current) {
                      audioElementRef.current.pause()
                      audioElementRef.current.currentTime = 0
                      audioElementRef.current = null
                    }
                    setPlayingQuestion(false)
                  }
                  if (recognitionRef.current) {
                    try {
                      recognitionRef.current.stop()
                    } catch (e: any) {
                      console.error('éŸ³å£°èªè­˜ã®åœæ­¢ã‚¨ãƒ©ãƒ¼:', e)
                    } finally {
                      isRecognitionActiveRef.current = false
                      setListening(false)
                    }
                  }
                  if (processing) setProcessing(false)
                  if (silenceTimeoutRef.current) clearTimeout(silenceTimeoutRef.current)
                  streamRef.current?.getTracks().forEach(track => track.stop())
                  streamRef.current = null
                  if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
                    try {
                      mediaRecorderRef.current.stop()
                    } catch (e: any) { console.error('éŒ²éŸ³ã®åœæ­¢ã‚¨ãƒ©ãƒ¼:', e) }
                  }
                  console.log('â¹ï¸ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ')
                }}
                className="w-full"
                variant="outline"
                size="sm"
              >
                <SquareIcon className="w-4 h-4 mr-2" />
                åœæ­¢
              </Button>
            </div>
          )}
          
          {/* çŠ¶æ…‹è¡¨ç¤º */}
          {!isInterviewComplete && questions.length > 0 && (
            <div className="mt-2 px-3 py-2 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-800 rounded-lg">
              <p className="text-xs text-blue-800 dark:text-blue-200">
                ğŸ¤ æœ¬ç•ªã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
                {listening && <span className="ml-2">ğŸ¤ éŸ³å£°èªè­˜ä¸­...</span>}
                {playingQuestion && <span className="ml-2">ğŸ”Š è³ªå•èª­ã¿ä¸Šã’ä¸­...</span>}
                {processing && <span className="ml-2">â³ å‡¦ç†ä¸­...</span>}
              </p>
            </div>
          )}
          
          {/* é€²æ—ãƒ¡ãƒ¼ã‚¿ãƒ¼ */}
          {!isInterviewComplete && questions.length > 0 && interview?.objective && (
            <div className="mt-4 space-y-2">
              {(() => {
                const overallCompletionRate = progressEvaluation?.overallCompletionRate || 0
                const progressPercentage = overallCompletionRate
                const objectiveItems = interview?.objective ? interview.objective.split('\n').map((line: string) => line.trim()).filter((line: string) => line.length > 0).map((line: string) => line.replace(/^[-*â€¢]\s*/, '').trim()).filter((line: string) => line.length > 0) : []
                const totalItems = objectiveItems.length || 1
                const completedItems = progressEvaluation?.items ? progressEvaluation.items.filter((item: any) => item.status === 'complete').length : 0
                const partialItems = progressEvaluation?.items ? progressEvaluation.items.filter((item: any) => item.status === 'partial').length : 0
                const remainingItems = totalItems - completedItems - partialItems
                
                const calculateEstimatedTime = () => {
                  if (!startTime || overallCompletionRate === 0 || overallCompletionRate >= 100) return null
                  const now = new Date()
                  const elapsed = (now.getTime() - startTime.getTime()) / 1000 / 60
                  const progressPerMinute = overallCompletionRate / elapsed
                  const remainingProgress = 100 - overallCompletionRate
                  const estimatedRemainingMinutes = remainingProgress / progressPerMinute
                  if (estimatedRemainingMinutes < 1) return 'ã‚ã¨æ•°åˆ†'
                  if (estimatedRemainingMinutes < 60) return `ã‚ã¨ç´„${Math.ceil(estimatedRemainingMinutes)}åˆ†`
                  const hours = Math.floor(estimatedRemainingMinutes / 60)
                  const minutes = Math.ceil(estimatedRemainingMinutes % 60)
                  return `ã‚ã¨ç´„${hours}æ™‚é–“${minutes > 0 ? `${minutes}åˆ†` : ''}`
                }
                const estimatedTime = calculateEstimatedTime()
                
                return (
                  <>
                    <div className="flex items-center justify-between text-xs text-gray-600 dark:text-gray-400">
                      <span>
                        {evaluatingProgress ? (
                          <span className="flex items-center gap-1"><LoaderIcon className="w-3 h-3 animate-spin" /> è©•ä¾¡ä¸­...</span>
                        ) : (
                          <span>
                            {completedItems > 0 && `${completedItems}é …ç›®å®Œäº†`}
                            {completedItems > 0 && partialItems > 0 && ' / '}
                            {partialItems > 0 && `${partialItems}é …ç›®éƒ¨åˆ†å›ç­”`}
                            {completedItems === 0 && partialItems === 0 && 'èããŸã„ã“ã¨ã‚’ç¢ºèªä¸­...'}
                          </span>
                        )}
                      </span>
                      <span>{Math.round(progressPercentage)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 dark:bg-gray-700 rounded-full h-2.5 overflow-hidden">
                      <div
                        className="bg-gradient-to-r from-blue-500 to-purple-600 h-2.5 rounded-full transition-all duration-500 ease-out"
                        style={{ width: `${progressPercentage}%` }}
                      />
                    </div>
                    <div className="flex items-center justify-between text-xs">
                      {progressPercentage < 100 ? (
                        <>
                          <span className="text-gray-600 dark:text-gray-400">
                            {remainingItems > 0 && `æ®‹ã‚Š${remainingItems}é …ç›®`}
                            {remainingItems === 0 && partialItems > 0 && 'æ·±æ˜ã‚ŠãŒå¿…è¦ãªé …ç›®ã‚ã‚Š'}
                            {remainingItems === 0 && partialItems === 0 && 'ã»ã¼å®Œäº†'}
                          </span>
                          {estimatedTime && <span className="text-blue-600 dark:text-blue-400 font-medium">{estimatedTime}</span>}
                        </>
                      ) : (
                        <span className="text-green-600 dark:text-green-400 font-medium">èããŸã„ã“ã¨ã¯å…¨ã¦èã‘ã¾ã—ãŸ</span>
                      )}
                    </div>
                    {progressEvaluation?.summary && <p className="text-xs text-gray-500 dark:text-gray-500 mt-1">{progressEvaluation.summary}</p>}
                  </>
                )
              })()}
            </div>
          )}
        </div>
      </div>

      {/* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ */}
      <div className="max-w-md mx-auto px-4 py-6 space-y-6">
        {/* ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« */}
        {interviewerProfile && (
          <div className="flex items-center gap-4 bg-white dark:bg-gray-800 rounded-lg p-4 shadow-sm">
            {interviewerProfile.photoURL ? (
              <div className="relative w-16 h-16 rounded-full overflow-hidden flex-shrink-0">
                <Image src={interviewerProfile.photoURL} alt={interviewerProfile.name || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'} fill className="object-cover" />
              </div>
            ) : (
              <div className="w-16 h-16 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center flex-shrink-0">
                <span className="text-white text-xl font-bold">{interviewerProfile.name?.charAt(0) || 'I'}</span>
              </div>
            )}
            <div className="flex-1 min-w-0">
              <p className="font-semibold text-gray-900 dark:text-gray-100">{interviewerProfile.name || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'}</p>
              {interviewerProfile.role && <p className="text-sm text-gray-600 dark:text-gray-400">{interviewerProfile.role}</p>}
            </div>
          </div>
        )}

        {/* ä¼šè©±å±¥æ­´ */}
        <div className="space-y-4">
          {messages.map((message, index) => (
            <div key={message.id || index} className={`flex gap-3 ${message.role === 'interviewer' ? 'justify-start' : 'justify-end'}`}>
              {message.role === 'interviewer' && interviewerProfile && (
                <div className="flex-shrink-0">
                  {interviewerProfile.photoURL ? (
                    <div className="relative w-10 h-10 rounded-full overflow-hidden">
                      <Image src={interviewerProfile.photoURL} alt={interviewerProfile.name || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'} fill className="object-cover" />
                    </div>
                  ) : (
                    <div className="w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center">
                      <span className="text-white text-sm font-bold">{interviewerProfile.name?.charAt(0) || 'I'}</span>
                    </div>
                  )}
                </div>
              )}
              <div className={`max-w-[80%] rounded-lg px-4 py-3 ${message.role === 'interviewer' ? 'bg-blue-50 dark:bg-blue-900/20' : 'bg-gray-200 dark:bg-gray-700'} text-gray-900 dark:text-gray-100`}>
                <p className="text-sm whitespace-pre-wrap break-words">{message.content}</p>
              </div>
            </div>
          ))}

          {listening && currentTranscript && (
            <div className="flex gap-3 justify-end">
              <div className="max-w-[80%] rounded-lg px-4 py-3 bg-gray-200 dark:bg-gray-700 text-gray-900 dark:text-gray-100 opacity-70">
                <p className="text-sm whitespace-pre-wrap break-words italic">{currentTranscript}</p>
              </div>
            </div>
          )}

          {processing && (
            <div className="flex gap-3 justify-start">
              {interviewerProfile && (
                <div className="flex-shrink-0">
                  {interviewerProfile.photoURL ? (
                    <div className="relative w-10 h-10 rounded-full overflow-hidden">
                      <Image src={interviewerProfile.photoURL} alt={interviewerProfile.name || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'} fill className="object-cover" />
                    </div>
                  ) : (
                    <div className="w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center">
                      <span className="text-white text-sm font-bold">{interviewerProfile.name?.charAt(0) || 'I'}</span>
                    </div>
                  )}
                </div>
              )}
              <div className="bg-blue-50 dark:bg-blue-900/20 rounded-lg px-4 py-3">
                <div className="flex items-center gap-1">
                  <span className="text-gray-600 dark:text-gray-400 text-sm">è³ªå•ã‚’æº–å‚™ä¸­</span>
                  <span className="inline-flex gap-1 ml-2">
                    <span className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce" style={{ animationDelay: '0ms' }}></span>
                    <span className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce" style={{ animationDelay: '150ms' }}></span>
                    <span className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce" style={{ animationDelay: '300ms' }}></span>
                  </span>
                </div>
              </div>
            </div>
          )}

          {isInterviewComplete && questions.length > 0 && (
            <div className="flex gap-3 justify-start">
              {interviewerProfile && (
                <div className="flex-shrink-0">
                  {interviewerProfile.photoURL ? (
                    <div className="relative w-10 h-10 rounded-full overflow-hidden">
                      <Image src={interviewerProfile.photoURL} alt={interviewerProfile.name || 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼'} fill className="object-cover" />
                    </div>
                  ) : (
                    <div className="w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center">
                      <span className="text-white text-sm font-bold">{interviewerProfile.name?.charAt(0) || 'I'}</span>
                    </div>
                  )}
                </div>
              )}
              <div className="bg-green-50 dark:bg-green-900/20 rounded-lg px-4 py-3">
                <p className="text-sm text-gray-900 dark:text-gray-100">
                  âœ… ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼ã™ã¹ã¦ã®è³ªå•ã«ã”å›ç­”ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
                </p>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
    )}
    </>
  )
}