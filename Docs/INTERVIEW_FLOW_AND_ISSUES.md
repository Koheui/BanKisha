# インタビューシステムのフロー・仕様・問題点

## 目次
1. [システム概要](#システム概要)
2. [ナレッジベースの活用](#ナレッジベースの活用)
3. [インタビュー生成フロー](#インタビュー生成フロー)
4. [インタビューフロー](#インタビューフロー)
5. [主要コンポーネント](#主要コンポーネント)
6. [APIエンドポイント](#apiエンドポイント)
7. [状態管理](#状態管理)
8. [現在の問題点](#現在の問題点)
9. [技術的な詳細](#技術的な詳細)

---

## システム概要

音声ベースのインタビューシステムで、以下の機能を提供：
- 音声認識による応答の取得
- テキスト読み上げ（TTS）による質問の再生
- AIによる質問生成・相槌生成・回答評価
- リアルタイムでの対話管理

---

## ナレッジベースの活用

### ナレッジベースの種類

システムでは、2種類のナレッジベースを活用します：

#### 1. スキルナレッジベース（Skill Knowledge Base）

**役割:**
- 質問設計・対話設計のベストプラクティスを提供
- インタビューの質を向上させるための思考の起点
- 効果的な質問の作り方、対話の流れの設計方法、相手が話しやすい質問のテクニックを含む

**特徴:**
- `type === 'skill'` またはファイル名に `skill` または `スキル` が含まれる
- `isEditOnly === true` の場合は、インタビュー質問生成では使用されない（記事編集時のみ使用）
- インタビュー生成時に自動的に取得される（ユーザーが選択する必要はない）

**取得方法:**
```typescript
// app/dashboard/interviews/new/page.tsx
const skillKBs = await getSkillKnowledgeBases()
const knowledgeBaseIds = skillKBs.map(kb => kb.id)
```

**コンテキストの生成:**
- スキルナレッジベースは最大50個のchunksを取得
- 各chunkは最大8000文字まで使用（質問設計に重要）
- プロンプトの最初に配置され、「思考の起点」として機能

#### 2. ユーザーナレッジベース（User Knowledge Base）

**役割:**
- 会社固有の情報を提供
- インタビュー対象の企業や個人に関する参考情報
- 質問生成時のコンテキストとして使用

**特徴:**
- `type !== 'skill'` かつファイル名に `skill` または `スキル` が含まれない
- ユーザーが手動で選択する必要がある（現在の実装では自動取得されない）
- 各chunkは最大2000文字まで使用

**コンテキストの生成:**
- ユーザーナレッジベースは最大20個のchunksを取得
- 各chunkは最大2000文字まで使用

### ナレッジベースの取得と処理

#### 質問生成時の処理（`/api/interview/generate-questions`）

1. **ナレッジベースIDの取得**
   - スキルナレッジベースは自動的に取得
   - ユーザーナレッジベースは `knowledgeBaseIds` パラメータで渡される（現在は未使用）

2. **ナレッジベースの分類**
   ```typescript
   const isSkillKB = kbData?.type === 'skill' || 
                    kbData?.fileName?.toLowerCase().includes('skill') || 
                    kbData?.fileName?.toLowerCase().includes('スキル')
   ```

3. **Chunksの取得**
   - スキルナレッジベース: 最大50個のchunks
   - ユーザーナレッジベース: 最大20個のchunks

4. **コンテキストの生成**
   ```typescript
   // スキルナレッジベースのコンテキスト
   skillKnowledgeContext = skillKBs.map(kb => {
     let context = `【${kb?.fileName}】\n概要: ${kb?.summary}\n活用方法: ${kb?.usageGuide}`
     if (kb?.chunks && kb.chunks.length > 0) {
       context += `\n\n【質問設計・対話設計のベストプラクティス】\n${kb.chunks.substring(0, 8000)}`
     }
     return context
   }).join('\n\n')
   
   // ユーザーナレッジベースのコンテキスト
   userKBContext = userKBs.map(kb => {
     let context = `【${kb?.fileName}】\n概要: ${kb?.summary}\n活用方法: ${kb?.usageGuide}`
     if (kb?.chunks && kb.chunks.length > 0) {
       context += `\n\n【参考コンテンツ】\n${kb.chunks.substring(0, 2000)}`
     }
     return context
   }).join('\n\n')
   ```

5. **プロンプトへの組み込み**
   - スキルナレッジベースはプロンプトの最初に配置
   - 「思考の起点」として機能し、質問設計の原則と手法を提供
   - ユーザーナレッジベースは参考情報として後半に配置

### ナレッジベースの活用タイミング

#### 1. インタビュー生成時（`/api/interview/generate-questions`）

**スキルナレッジベースの活用:**
- プロンプトの最初に配置
- 「思考の起点」として機能
- 以下の原則を提供：
  - 対話を重視する
  - ゴールを意識する
  - 深掘りを重視する
  - 相手が話しやすい質問のテクニック

**プロンプト例:**
```
【最重要：思考の起点 - 質問設計・対話設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容]

**⚠️ 最重要**: 上記のスキルナレッジベースは、質問設計における思考の起点です。
**必ず最初にこの内容を参照し、その原則と手法に基づいて質問を生成してください。**
```

#### 2. 追加質問生成時（`/api/interview/generate-follow-up`）

**スキルナレッジベースの活用:**
- 最大30個のchunksを取得
- 各chunkは最大5000文字まで使用
- フォローアップ質問のテクニックを提供

**プロンプト例:**
```
【重要：質問設計・対話設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容]

このスキルナレッジベースには、効果的なフォローアップ質問の作り方、
対話の流れの設計方法、相手が話しやすい質問のテクニックなどが含まれています。
**必ずこの内容を参考にして質問を生成してください。**
```

#### 3. 動的質問生成時（`/api/interview/generate-next-question`）

**スキルナレッジベースの活用:**
- 最大50個のchunksを取得
- 各chunkは最大10000文字まで使用
- 対話設計・質問設計のベストプラクティスを提供

**プロンプト例:**
```
【最重要：思考の起点 - 対話設計・質問設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容]

**⚠️ 最重要**: 上記のスキルナレッジベースは、対話設計における思考の起点です。
**必ず最初にこの内容を参照し、その原則と手法に基づいて次の質問を生成してください。**
```

### ナレッジベースの影響範囲

#### 質問生成への影響

1. **質問の質の向上**
   - スキルナレッジベースの原則に基づいた質問設計
   - 対話を重視した質問の流れ
   - 深掘りを意識した質問の構成

2. **質問の表現の改善**
   - 自然な会話形式
   - 相手が話しやすい質問のテクニック
   - ゴールを意識した質問の選定

3. **質問の順序の最適化**
   - 会話の流れを意識した順序
   - 前の回答に自然に繋がる質問設計

#### インタビュー実施への影響

1. **追加質問の生成**
   - スキルナレッジベースのテクニックを活用
   - より効果的なフォローアップ質問

2. **動的質問の生成**
   - 会話の流れに基づいた自然な質問
   - スキルナレッジベースの原則に基づいた質問選定

3. **相槌の生成**
   - 現在はナレッジベースを使用していない
   - 将来的にはスキルナレッジベースの反応パターンを活用可能

---

## インタビュー生成フロー

### 1. インタビュー情報の入力

**画面: `app/dashboard/interviews/new/page.tsx`**

ユーザーが以下の情報を入力：
- タイトル
- インタビュー対象者情報（名前、会社名、役職、部署など）
- カテゴリ（ビジネス、エンジニア、クリエイター、ライフスタイル、カジュアル、その他）
- ターゲット読者
- 掲載メディア
- 取材の目的
- 具体的な質問（箇条書き）
- インタビュアーの選択
- 質問数（デフォルト10問、3〜30問の範囲）

### 2. インタビュー情報の保存

**処理: `handleSave()`**

1. 必須項目のチェック
   - タイトル
   - インタビュアーの選択

2. Firestoreへの保存
   ```typescript
   const interviewData = {
     companyId: user.companyId,
     interviewerId: selectedInterviewerId,
     interviewerName: selectedInterviewer.name,
     // ... その他の情報
     status: 'active',
     updatedAt: serverTimestamp(),
   }
   await setDoc(doc(getFirebaseDb(), 'interviews', interviewId), interviewData)
   ```

3. `interviewId` の取得
   - 新規作成時は自動生成
   - 編集時は既存のIDを使用

### 3. 質問生成の実行

**処理: `handleGenerateQuestionsWithKnowledge()`**

1. **スキルナレッジベースの自動取得**
   ```typescript
   const skillKBs = await getSkillKnowledgeBases()
   const knowledgeBaseIds = skillKBs.map(kb => kb.id)
   ```

2. **質問生成APIの呼び出し**
   ```typescript
   const response = await fetch('/api/interview/generate-questions', {
     method: 'POST',
     body: JSON.stringify({
       interviewId: interviewId,
       category: category,
       targetAudience: targetAudience,
       mediaType: mediaType,
       interviewPurpose: interviewPurpose,
       objective: objective,
       interviewerPrompt: currentInterviewer.prompt || '',
       interviewerName: currentInterviewer.name || '',
       knowledgeBaseIds: knowledgeBaseIds, // スキルナレッジベースのID
       questionCount: questionCount,
       // ... その他の情報
     }),
   })
   ```

### 4. 質問生成APIの処理（`/api/interview/generate-questions`）

#### 4.1 ナレッジベースの取得と処理

1. **ナレッジベースの分類**
   - スキルナレッジベースとユーザーナレッジベースに分類
   - `isEditOnly === true` のスキルは除外

2. **Chunksの取得**
   - スキルナレッジベース: 最大50個のchunks
   - ユーザーナレッジベース: 最大20個のchunks

3. **コンテキストの生成**
   - スキルナレッジベース: 最大8000文字/ナレッジベース
   - ユーザーナレッジベース: 最大2000文字/ナレッジベース

#### 4.2 プロンプトの構築

1. **スキルナレッジベースの配置**
   - プロンプトの最初に配置
   - 「思考の起点」として機能

2. **基本情報の追加**
   - カテゴリの説明
   - ターゲット読者
   - 掲載メディア
   - 取材の目的
   - 具体的な質問

3. **インタビュアー情報の追加**
   - インタビュアーの特徴・口調
   - インタビュアー名

4. **ユーザーナレッジベースの追加**
   - 参考情報として後半に配置

#### 4.3 質問の生成

1. **Gemini APIの呼び出し**
   ```typescript
   const model = genAI.getGenerativeModel({
     model: 'gemini-2.5-flash',
     generationConfig: {
       temperature: 0.7,
     },
   })
   const result = await model.generateContent(prompt)
   ```

2. **質問のパース**
   - 生成されたテキストを改行で分割
   - 番号（1. 2. など）を除去
   - 空行を除去

3. **オープニングと本題の質問の分離**
   - オープニング（挨拶・自己紹介）は質問数に含めない
   - 本題の質問のみを質問数としてカウント

### 5. 生成された質問の確認と保存

1. **質問の表示**
   - 生成された質問をテキストエリアに表示
   - 質問の説明（explanation）を表示

2. **質問の確認**
   - ユーザーが質問を確認
   - 必要に応じて編集

3. **質問の保存**
   ```typescript
   const questionsText = questionsList.map((q, i) => `${i + 1}. ${q}`).join('\n')
   await updateDoc(doc(getFirebaseDb(), 'interviews', interviewId), {
     questions: questionsText,
     updatedAt: serverTimestamp(),
   })
   ```

### 6. インタビューの開始

1. **インタビューページへの遷移**
   ```typescript
   router.push(`/interview/${interviewId}`)
   ```

2. **インタビューデータの読み込み**
   - Firestoreからインタビューセッションを取得
   - 質問リストをパース
   - インタビュアープロファイルを取得

---

## インタビューフロー

### 1. 初期化フェーズ

1. **インタビューデータの読み込み**
   - Firestoreからインタビューセッションを取得
   - インタビュアープロファイルを取得
   - 質問リストをパース

2. **初期化処理**
   - キャンセル済みまたはメッセージが存在する場合、初期化を実行
   - メッセージの削除（権限がある場合）
   - ローカル状態のリセット

3. **メッセージリスナーの設定**
   - Firestoreのメッセージコレクションを監視
   - リアルタイムでメッセージの更新を取得

### 2. マイクテスト・音声確認フェーズ

1. **マイクテストの実施**
   - `performMicTest()` 関数でマイクへのアクセスを要求
   - 録音テストを実施（1秒間）
   - マイクが正常に動作することを確認

2. **音声・マイク確認メッセージの再生**
   - 「はじめにマイクのチェックを行います。まずはあなたのお名前を教えて下さい。」
   - 音声認識を開始して応答を待つ

3. **名前の応答処理**
   - ユーザーの名前を取得
   - メッセージとして保存
   - インタビュアーの反応を生成・再生（「ありがとうございます。」など）
   - `audioCheckCompleted` を `true` に設定

### 3. 導入メッセージフェーズ

1. **導入メッセージの再生**
   - 「本日はお時間をいただき、ありがとうございます。私、[インタビュアー名]と申します。それでは、よろしくお願いいたします。」
   - 短縮版（目的・ターゲット読者・メディアの説明は含まない）

2. **最初の質問の決定**
   - 質問0が自己紹介の内容かどうかをチェック
   - 自己紹介の内容の場合、質問1から開始
   - そうでない場合、質問0から開始

### 4. 質問・応答フェーズ

1. **質問の再生**
   - `handlePlayQuestion(questionIndex)` で質問を再生
   - TTS APIで音声を生成
   - 音声再生が完了したら、メッセージとして保存
   - 音声認識を開始して応答を待つ

2. **応答の処理**
   - `processResponse(transcript)` で応答を処理
   - メッセージとして保存
   - 相槌を生成・再生（非同期）
   - 次の質問への進行を決定

3. **次の質問への進行**
   - 通常の質問リストに次の質問がある場合：
     - すぐに次の質問に進む（相槌生成・回答評価・追加質問生成をスキップ）
     - `currentQuestionIndex` を更新
     - 次の質問を再生
   - 次の質問がない場合：
     - 回答評価を実行（非同期）
     - 追加質問生成を試行
     - それでも質問がない場合、動的質問生成を試行

### 5. 終了フェーズ

1. **インタビューの完了**
   - 全ての質問が終了した場合
   - 「もし言い残したことがあればぜひお話ください。」を再生
   - インタビューのステータスを更新

2. **中断処理**
   - ユーザーが停止ボタンをクリック
   - メッセージの削除（権限がある場合）
   - ローカル状態のリセット

---

## 主要コンポーネント

### `app/interview/[id]/page.tsx`

メインのインタビューページコンポーネント。

#### 主要な状態変数

- `interview`: インタビューセッション情報
- `interviewerProfile`: インタビュアーのプロファイル
- `questions`: 質問リスト（配列）
- `currentQuestionIndex`: 現在の質問インデックス
- `messages`: メッセージリスト
- `audioCheckCompleted`: 音声・マイク確認が完了したか
- `hasStarted`: インタビューが開始されたか
- `listening`: 音声認識中か
- `playingQuestion`: 質問を再生中か
- `processing`: 処理中か

#### 主要なRef

- `questionsRef`: 質問リストのref版（クロージャ問題の回避）
- `currentQuestionIndexRef`: 現在の質問インデックスのref版
- `audioCheckCompletedRef`: 音声・マイク確認完了のref版
- `messagesLengthRef`: メッセージ数のref版
- `isInitializingRef`: 初期化中かどうかのref版
- `interviewerProfileRef`: インタビュアープロファイルのref版

#### 主要な関数

- `loadInterviewData()`: インタビューデータを読み込む
- `setupMessagesListener()`: メッセージリスナーを設定
- `handleStartInterview()`: インタビューを開始
- `performMicTest()`: マイクテストを実施
- `handlePlayAudioCheck()`: 音声・マイク確認メッセージを再生
- `handlePlayIntroduction()`: 導入メッセージを再生
- `handlePlayQuestion(questionIndex)`: 質問を再生
- `processResponse(transcript)`: 応答を処理
- `startListening()`: 音声認識を開始
- `initializeSpeechRecognition()`: 音声認識を初期化

---

## APIエンドポイント

### `/api/interview/generate-questions`
質問リストを生成するAPI。

**入力:**
- `interviewId`: インタビューID
- `category`: カテゴリ
- `targetAudience`: ターゲット読者
- `mediaType`: 掲載メディア
- `interviewPurpose`: 取材の目的
- `objective`: 具体的な質問
- `interviewerName`: インタビュアー名
- `questionCount`: 質問数（デフォルト10問）

**出力:**
- 質問リスト（オープニングと本題の質問を含む）

**注意:**
- オープニング（挨拶・自己紹介）は質問数に含めない
- 本題の質問のみを質問数としてカウント

### `/api/interview/generate-reaction`
相槌を生成するAPI。

**入力:**
- `userResponse`: ユーザーの応答
- `interviewerPrompt`: インタビュアーのプロンプト
- `reactionPatterns`: 反応パターン

**出力:**
- `reaction`: 相槌テキスト

### `/api/interview/evaluate-response`
回答を評価するAPI。

**入力:**
- `question`: 質問
- `userResponse`: ユーザーの応答
- `interviewObjective`: インタビューの目的
- `conversationHistory`: 会話履歴

**出力:**
- `evaluation`: 評価結果（`isSufficient`, `suggestedAngle`, `missingElements`など）

### `/api/interview/generate-follow-up`
追加質問を生成するAPI。

**入力:**
- `question`: 現在の質問
- `userResponse`: ユーザーの応答
- `interviewObjective`: インタビューの目的
- `interviewerPrompt`: インタビュアーのプロンプト
- `knowledgeBaseIds`: ナレッジベースID
- `conversationHistory`: 会話履歴
- `needsMoreInfo`: 追加情報が必要か
- `suggestedAngle`: 推奨される角度
- `introductionMessage`: 導入メッセージ（重複を避けるため）

**出力:**
- `question`: 追加質問テキスト

### `/api/interview/generate-next-question`
動的質問を生成するAPI。

**入力:**
- `conversationHistory`: 会話履歴
- `interviewPurpose`: 取材の目的
- `targetAudience`: ターゲット読者
- `mediaType`: 掲載メディア
- `objective`: インタビューの目的
- `knowledgeBaseIds`: ナレッジベースID
- `introductionMessage`: 導入メッセージ
- `interviewerName`: インタビュアー名

**出力:**
- `question`: 動的質問テキスト

### `/api/text-to-speech`
テキストを音声に変換するAPI。

**入力:**
- `text`: テキスト
- `voiceType`: 音声タイプ（デフォルト: 'Puck'）
- `speed`: 速度（デフォルト: 1.0）

**出力:**
- 音声データ（Blob）

---

## 状態管理

### 状態の同期

Reactの状態とRefを同期させることで、非同期処理でのクロージャ問題を回避：

```typescript
// State
const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0)
const [questions, setQuestions] = useState<string[]>([])

// Ref
const currentQuestionIndexRef = useRef<number>(0)
const questionsRef = useRef<string[]>([])

// 同期
useEffect(() => {
  currentQuestionIndexRef.current = currentQuestionIndex
}, [currentQuestionIndex])

useEffect(() => {
  questionsRef.current = questions
}, [questions])
```

### メッセージリスナー

Firestoreのメッセージコレクションを監視し、リアルタイムでメッセージを取得：

```typescript
const unsubscribe = onSnapshot(q, (snapshot) => {
  const newMessages = snapshot.docs.map(doc => ({
    id: doc.id,
    ...doc.data(),
    timestamp: doc.data().timestamp?.toDate(),
  })) as Message[]
  
  setMessages(newMessages)
  messagesLengthRef.current = newMessages.length
})
```

---

## 現在の問題点

### 1. 質問0が自己紹介の内容になっている

**問題:**
- 質問生成APIで生成された質問リストの最初の質問（質問0）が、自己紹介の内容（「本日はお時間いただき、ありがとうございます。私、[インタビュアー名]と申します。」）になっている
- これは質問ではなく、導入メッセージとして別途再生されるべき内容

**影響:**
- 質問0が自己紹介の内容の場合、ユーザーが応答しても次の質問に進まない
- 同じ質問が繰り返される

**現在の対策:**
- 質問0が自己紹介の内容かどうかをチェックし、該当する場合は質問1から開始
- しかし、判定が不十分で、まだ問題が発生している

### 2. 質問1で終わってしまう

**問題:**
- 質問1に答えた後、次の質問（質問2）に進まない
- 全ての質問が実行されない

**影響:**
- インタビューが途中で終了してしまう
- ユーザーが全ての質問に答えることができない

**考えられる原因:**
- `currentQuestionIndexRef.current` が正しく更新されていない
- `questionsRef.current` が正しく更新されていない
- 次の質問への進行条件が満たされていない

### 3. 同じ質問が繰り返される

**問題:**
- 同じ質問が4回も繰り返される
- 質問0が自己紹介の内容の場合、質問0に答えた後、また質問0が再生される

**影響:**
- ユーザーが混乱する
- インタビューがスムーズに進まない

**考えられる原因:**
- `audioCheckCompleted` が `false` のままになっている
- `messagesLengthRef.current` が `0` のままになっている
- マイクチェック処理に戻ってしまう

### 4. 音声が別人になる

**問題:**
- 相槌や反応（「ありがとうございます。」など）が、インタビュアーの音声設定ではなく、デフォルトの音声設定で再生される

**影響:**
- インタビュアーの一貫性が失われる
- ユーザーが混乱する

**現在の対策:**
- 相槌生成時にインタビュアーの音声設定を使用するように修正
- しかし、まだ問題が発生している可能性がある

### 5. ヴォイスチャットになっていない

**問題:**
- 対話がスムーズに進まない
- 応答に対する反応が適切でない
- 質問が次に進まない

**影響:**
- ユーザー体験が悪い
- インタビューが自然な対話にならない

**考えられる原因:**
- 状態管理が複雑で、正しく動作していない
- 非同期処理のタイミングが適切でない
- 質問の進行ロジックに問題がある

### 6. 質問生成の問題

**問題:**
- 質問生成APIで生成された質問が、期待通りでない
- オープニング（挨拶・自己紹介）が質問リストに含まれている
- 同じ内容の質問が繰り返される

**影響:**
- インタビューの品質が低下する
- ユーザーが混乱する

**現在の対策:**
- オープニングを質問リストから除外するように修正
- しかし、既存のインタビューには古い質問データが残っている

---

## 技術的な詳細

### 音声認識

- Web Speech API（`SpeechRecognition` / `webkitSpeechRecognition`）を使用
- 日本語（`ja-JP`）を認識
- `continuous: true` で連続認識を有効化
- `interimResults: true` で中間結果を取得

### 音声再生

- `/api/text-to-speech` APIで音声を生成
- `HTMLAudioElement` で音声を再生
- 音声再生が完了したら、次の処理に進む

### メッセージ管理

- Firestoreの `interviews/{interviewId}/messages` コレクションに保存
- メッセージには以下の情報が含まれる：
  - `role`: 'interviewer' または 'interviewee'
  - `content`: テキスト内容
  - `audioUrl`: 音声URL（Blob URL）
  - `timestamp`: タイムスタンプ

### 質問の進行ロジック

1. 通常の質問リストに次の質問がある場合：
   - すぐに次の質問に進む
   - 相槌生成・回答評価・追加質問生成をスキップ
   - 待機時間を短縮（500ms）

2. 次の質問がない場合：
   - 回答評価を実行（非同期）
   - 追加質問生成を試行
   - それでも質問がない場合、動的質問生成を試行

### 初期化処理

- キャンセル済みまたはメッセージが存在する場合、初期化を実行
- メッセージの削除（権限がある場合、最大3回試行）
- ローカル状態のリセット：
  - `currentQuestionIndex` → 0
  - `audioCheckCompleted` → false
  - `hasStarted` → false
  - `messages` → []
  - その他の状態もリセット

---

## 改善提案

### 1. 質問0の自動スキップ機能の強化

- 質問0が自己紹介の内容かどうかの判定をより確実にする
- 自己紹介のキーワードを追加
- 質問0が自己紹介の内容の場合、確実に質問1から開始

### 2. 質問進行ロジックの改善

- `currentQuestionIndexRef.current` と `questionsRef.current` の更新を確実にする
- 次の質問への進行条件を明確にする
- デバッグログを追加して、問題の原因を特定しやすくする

### 3. 状態管理の簡素化

- 状態管理を簡素化して、バグを減らす
- RefとStateの同期を確実にする
- 非同期処理での状態の取得を確実にする

### 4. 音声設定の一貫性

- 全ての音声再生で、インタビュアーの音声設定を使用する
- デフォルト値のフォールバックを確実にする

### 5. 質問生成APIの改善

- オープニングを質問リストから確実に除外する
- 既存のインタビューでも、質問0が自己紹介の内容の場合は自動的にスキップする

---

## ファイル構成

```
app/
├── interview/
│   └── [id]/
│       └── page.tsx          # メインのインタビューページ
└── api/
    └── interview/
        ├── generate-questions/    # 質問生成API
        ├── generate-reaction/     # 相槌生成API
        ├── evaluate-response/     # 回答評価API
        ├── generate-follow-up/    # 追加質問生成API
        └── generate-next-question/ # 動的質問生成API
```

---

## デバッグ方法

### コンソールログ

以下のログが出力される：
- `🔍 processResponse 状態確認`: 応答処理時の状態
- `🔍 質問0の内容チェック`: 質問0が自己紹介の内容かどうかのチェック
- `🔍 次の質問への進行チェック`: 次の質問への進行時の状態
- `✅ 次の質問に進みます`: 次の質問に進む場合
- `⚠️ 次の質問が存在しません`: 次の質問がない場合

### 状態の確認

以下の状態を確認：
- `currentQuestionIndex`: 現在の質問インデックス
- `questions.length`: 質問リストの長さ
- `audioCheckCompleted`: 音声・マイク確認が完了したか
- `messagesLength`: メッセージ数

---

## ナレッジベース・インタビュー生成・インタビュー実施の密接な関係

### 全体の流れ

```
┌─────────────────────────────────────────────────────────────┐
│ 1. ナレッジベースの準備                                        │
│    - スキルナレッジベース: 質問設計・対話設計のベストプラクティス │
│    - ユーザーナレッジベース: 会社固有の情報                      │
└─────────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────────┐
│ 2. インタビュー生成                                            │
│    - スキルナレッジベースを自動取得                             │
│    - プロンプトに組み込み（思考の起点として）                    │
│    - 質問リストを生成                                           │
└─────────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────────┐
│ 3. インタビュー実施                                            │
│    - 生成された質問リストを使用                                 │
│    - 追加質問生成時にスキルナレッジベースを活用                 │
│    - 動的質問生成時にスキルナレッジベースを活用                 │
└─────────────────────────────────────────────────────────────┘
```

### 各フェーズでのナレッジベースの活用

#### フェーズ1: インタビュー生成時

**スキルナレッジベースの役割:**
- 質問設計の思考の起点として機能
- 以下の原則を提供：
  - 対話を重視する
  - ゴールを意識する
  - 深掘りを重視する
  - 相手が話しやすい質問のテクニック

**プロンプトへの組み込み:**
```
【最重要：思考の起点 - 質問設計・対話設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容（最大8000文字/ナレッジベース）]

**⚠️ 最重要**: 上記のスキルナレッジベースは、質問設計における思考の起点です。
**必ず最初にこの内容を参照し、その原則と手法に基づいて質問を生成してください。**
```

**影響:**
- 生成される質問の質が向上
- 対話を重視した質問の流れ
- 深掘りを意識した質問の構成

#### フェーズ2: インタビュー実施時（追加質問生成）

**スキルナレッジベースの役割:**
- フォローアップ質問のテクニックを提供
- 会話の流れに基づいた自然な質問生成

**プロンプトへの組み込み:**
```
【重要：質問設計・対話設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容（最大5000文字）]

このスキルナレッジベースには、効果的なフォローアップ質問の作り方、
対話の流れの設計方法、相手が話しやすい質問のテクニックなどが含まれています。
**必ずこの内容を参考にして質問を生成してください。**
```

**影響:**
- より効果的なフォローアップ質問
- 会話の流れに自然に繋がる質問

#### フェーズ3: インタビュー実施時（動的質問生成）

**スキルナレッジベースの役割:**
- 対話設計・質問設計のベストプラクティスを提供
- 会話の流れに基づいた自然な質問生成

**プロンプトへの組み込み:**
```
【最重要：思考の起点 - 対話設計・質問設計のベストプラクティス（スキルナレッジベース）】
[スキルナレッジベースの内容（最大10000文字）]

**⚠️ 最重要**: 上記のスキルナレッジベースは、対話設計における思考の起点です。
**必ず最初にこの内容を参照し、その原則と手法に基づいて次の質問を生成してください。**
```

**影響:**
- 会話の流れに基づいた自然な質問
- スキルナレッジベースの原則に基づいた質問選定

### ナレッジベースの更新による影響

#### スキルナレッジベースの更新

**影響範囲:**
- 新規に生成されるインタビューの質問品質
- 追加質問生成時の質問品質
- 動的質問生成時の質問品質

**更新方法:**
- Firestoreの `knowledgeBases` コレクションで更新
- `chunks` サブコレクションで詳細情報を更新

#### ユーザーナレッジベースの更新

**影響範囲:**
- 新規に生成されるインタビューの質問内容
- 会社固有の情報に基づいた質問生成

**更新方法:**
- Firestoreの `knowledgeBases` コレクションで更新
- `chunks` サブコレクションで詳細情報を更新

### ナレッジベースの最適化

#### スキルナレッジベースの最適化

**推奨事項:**
- 質問設計の原則と手法を明確に記載
- 対話を重視する方法を具体的に説明
- 深掘り質問の例を豊富に含める
- 相手が話しやすい質問のテクニックを具体的に説明

**Chunksの最適化:**
- 各chunkは8000文字以内に収める
- 質問設計の原則と手法を中心に構成
- 具体的な例を含める

#### ユーザーナレッジベースの最適化

**推奨事項:**
- 会社固有の情報を明確に記載
- インタビュー対象者に関する情報を含める
- 業界や市場に関する情報を含める

**Chunksの最適化:**
- 各chunkは2000文字以内に収める
- 関連性の高い情報を中心に構成
- 具体的な事例を含める

---

## まとめ

現在のインタビューシステムは、音声ベースの対話を実現するための複雑な状態管理と非同期処理を含んでいます。主な問題は、質問の進行ロジックと状態管理にあります。特に、質問0が自己紹介の内容になっている問題と、質問1で終わってしまう問題が深刻です。

これらの問題を解決するには、状態管理の簡素化、質問進行ロジックの改善、デバッグログの追加などが必要です。

### ナレッジベースの重要性

ナレッジベース（特にスキルナレッジベース）は、インタビューシステムの品質を決定する重要な要素です：

1. **質問生成の質**: スキルナレッジベースの内容が、生成される質問の質を大きく左右します
2. **対話の自然さ**: スキルナレッジベースの原則に基づいて、自然な対話が実現されます
3. **深掘りの効果**: スキルナレッジベースのテクニックにより、効果的な深掘り質問が生成されます

### 今後の改善点

1. **ナレッジベースの管理機能の強化**
   - ナレッジベースの編集・更新機能
   - ナレッジベースの効果測定機能

2. **ユーザーナレッジベースの活用拡大**
   - インタビュー生成時にユーザーナレッジベースを選択可能にする
   - ユーザーナレッジベースの内容をより効果的に活用する

3. **ナレッジベースの最適化**
   - スキルナレッジベースの内容を継続的に改善
   - ユーザーナレッジベースの品質向上

---

## 変更履歴

### 2025-12-22: インタビューフローの安定化対応

`app/interview/[id]/page.tsx`に対して以下の修正を実施し、報告されていた問題点に対応しました。

1.  **質問リストの事前フィルタリング機能の追加**
    - **問題:** 質問リストの先頭に自己紹介文が含まれてしまい、インタビューが正しく開始されない。
    - **対応:** `loadInterviewData`関数内で、質問リストを読み込む際に自己紹介文を自動的に除去する`filterIntroductoryQuestions`関数を追加・適用しました。これにより、インタビューが始まる前に不要な導入文が取り除かれ、実際の質問のみが扱われるようになります。

2.  **応答処理ロジックの簡素化**
    - **問題:** 応答を処理する`processResponse`関数内に、自己紹介文を判定・スキップするための複雑な条件分岐が存在し、不具合の原因となっていた。
    - **対応:** 上記の事前フィルタリングを導入したことにより、不要になった自己紹介文の判定ロジックを`processResponse`関数から削除しました。これにより、コードが簡潔になり、応答処理が安定化しました。

3.  **音声設定の参照を修正**
    - **問題:** 相槌などの自動生成音声が、インタビュアーの指定した音声とは異なるデフォルト音声で再生されることがあった。
    - **対応:** 非同期で実行される音声生成処理において、最新の音声設定を確実に参照するよう、`interviewerProfile`のstateではなく`interviewerProfileRef`から設定を読み込むように修正しました。

4.  **デバッグログの追加**
    - **問題:** 状態遷移が複雑で、問題発生時の原因追跡が困難だった。
    - **対応:** `processResponse`関数の開始時に、現在の質問インデックスや各種状態を記録するログを追加し、今後のデバッグを容易にしました。

これらの変更により、インタビューが途中で停止する、同じ質問が繰り返される、といった主要な問題が解決され、全体の安定性が向上しました。